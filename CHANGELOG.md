# Changelog

All notable changes to Local LLM Kit will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added
- Future features and improvements will be listed here

## [0.1.0] - 2023-11-25

### Added
- Initial release of Local LLM Kit
- Chat and Completion API (OpenAI-compatible)
- Function calling with automatic execution
- Multiple model backend support:
  - Hugging Face Transformers
  - llama.cpp (GGUF models)
- Streaming response support
- Memory management with auto-truncation
- JSON mode and structured output
- Prompt formatting for different model architectures:
  - Llama 2 Chat
  - Mistral Instruct
  - Vicuna
  - ChatML
  - Plain Instruct
- Command line interface
- Basic examples and documentation 